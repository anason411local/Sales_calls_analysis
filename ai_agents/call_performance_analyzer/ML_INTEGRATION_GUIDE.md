# ğŸ¤– ML Insights Agent - Integration Guide

## Overview

The **ML Insights Agent** has been successfully integrated into the Call Performance Analyzer using a **ReAct (Reasoning + Acting) pattern**. This agent analyzes machine learning outputs and generates actionable insights that are automatically included in the final report.

---

## ğŸ¯ What It Does

### 1. **Analyzes ML Outputs**
- Correlation analysis (49 variables)
- Feature importance (Random Forest + XGBoost)
- SHAP explanations (model interpretability)
- Statistical tests (t-test, Mann-Whitney, Chi-square, Cohen's D)
- LIME local explanations
- Model performance metrics

### 2. **Generates Insights**
- Identifies top 10 most important variables
- Creates 20+ actionable insights with evidence
- Prioritizes by importance score
- Links insights to visualizations

### 3. **Embeds Visualizations**
- SHAP Waterfall plots
- Feature importance charts
- Correlation heatmaps
- Statistical effect sizes
- Model performance curves

### 4. **Produces Recommendations**
- Uses Gemini LLM to synthesize findings
- Generates 5-7 prioritized recommendations
- Provides implementation guidance
- Cross-validates with agentic AI insights

---

## ğŸš€ How to Use

### **Option 1: Automatic (Default)**

The ML Insights Agent runs automatically when you execute the Call Performance Analyzer:

```bash
cd ai_agents/call_performance_analyzer
python main.py
```

The agent will:
1. Analyze all calls (normal process)
2. **Automatically invoke ML Insights Agent** before report generation
3. Generate report with ML insights section
4. Embed visualizations in Markdown
5. Convert to DOCX

### **Option 2: Test ML Agent Separately**

To test the ML Insights Agent independently:

```bash
cd ai_agents/call_performance_analyzer
python test_ml_integration.py
```

This will:
- Initialize the ML Insights Agent
- Load ML data
- Generate insights
- Display summary
- Verify integration

---

## ğŸ“Š Report Structure

The final report now includes:

### **Main Report Sections** (Generated by Agentic AI)
1. Executive Summary
2. Agent-Level Performance
3. Call Pattern Analysis
4. Lead Quality Impact Analysis
5. LGS vs OMC Analysis
6. Daily Trends
7. Status/Outcome Analysis
8. Recommendations
9. Real Examples

### **NEW: ML Insights Section** (Generated by ML Agent)
10. ğŸ¤– **Machine Learning Insights**
    - Statistical Summary
    - Top 10 Most Important Variables
    - **Key ML Visualizations** (embedded images):
      - SHAP Waterfall Plot
      - Top 20 Variables Chart
      - SHAP Summary Beeswarm
      - Correlation vs Importance
      - Effect Sizes
      - ROC Curves
    - Key ML Insights (by category)
    - ML-Based Recommendations
    - ML Methodology

---

## ğŸ–¼ï¸ Embedded Visualizations

The following visualizations are automatically embedded in the Markdown report:

| Visualization | Description | Purpose |
|--------------|-------------|---------|
| **SHAP Waterfall** | Individual prediction explanation | Shows how each variable pushes calls toward short/long |
| **Top 20 Variables** | Feature importance ranking | Identifies most critical predictors |
| **SHAP Summary** | Overall feature impact | Shows patterns across all calls |
| **Correlation vs Importance** | Statistical vs ML comparison | Validates findings |
| **Effect Sizes** | Statistical significance | Shows practical differences |
| **ROC Curves** | Model performance | Demonstrates prediction accuracy |

### Image Format in Markdown

Images are embedded using relative paths compatible with Word conversion:

```markdown
![SHAP Waterfall Plot](ML V2/analysis_outputs/level1_variable/shap_05_rf_waterfall.png)
```

---

## ğŸ”§ Configuration

### ML Data Path

Default path: `../ML V2/analysis_outputs/level1_variable`

To change:

```python
# In orchestrator/batch_orchestrator.py
ml_agent = MLInsightsAgent(ml_data_path="custom/path/to/ml/data")
```

### Visualization Priority

To modify which visualizations are included, edit `agents/ml_insights_agent.py`:

```python
def _select_key_visualizations(self) -> List[str]:
    priority_viz = [
        "shap_05_rf_waterfall.png",  # Your priority 1
        "viz_06_top_20_variables.png",  # Your priority 2
        # Add more...
    ]
```

---

## ğŸ“ File Structure

```
ai_agents/call_performance_analyzer/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ analysis_nodes.py (existing)
â”‚   â””â”€â”€ ml_insights_agent.py (NEW - 600+ lines)
â”œâ”€â”€ orchestrator/
â”‚   â””â”€â”€ batch_orchestrator.py (MODIFIED - added ML agent call)
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ state.py (MODIFIED - added ml_insights field)
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ report_generator.py (MODIFIED - ML section generation)
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_templates.py (MODIFIED - ML insights parameter)
â”œâ”€â”€ test_ml_integration.py (NEW - test script)
â”œâ”€â”€ ML_INTEGRATION_SUMMARY.txt (NEW - technical summary)
â””â”€â”€ ML_INTEGRATION_GUIDE.md (NEW - this file)
```

---

## ğŸ” How It Works (ReAct Pattern)

### **REASONING Phase**

1. **Load ML Data**
   ```
   - Correlation CSVs
   - Feature importance CSVs
   - SHAP CSVs
   - Statistical test CSVs
   - LIME CSVs
   - Model metrics JSONs
   ```

2. **Analyze Components**
   ```
   - Top correlations (positive & negative)
   - Most important features (RF + XGB)
   - SHAP contributors
   - Statistically significant variables
   - LIME local importance
   ```

### **ACTING Phase**

3. **Generate Insights**
   ```
   - Create MLInsight objects
   - Assign importance scores
   - Link to visualizations
   - Add recommendations
   ```

4. **Synthesize with LLM**
   ```
   - Use Gemini to combine insights
   - Generate comprehensive recommendations
   - Prioritize by impact
   - Select key visualizations
   ```

5. **Integrate into Report**
   ```
   - Pass to report generator
   - LLM integrates ML + agentic AI
   - Append ML section
   - Embed images
   ```

---

## âœ… Verification Checklist

After running the analyzer, verify:

- [ ] Logs show: "ML INSIGHTS AGENT: STARTING ANALYSIS"
- [ ] Logs show: "Generated X key insights"
- [ ] Logs show: "ML INSIGHTS AGENT: ANALYSIS COMPLETE"
- [ ] Report includes "ğŸ¤– MACHINE LEARNING INSIGHTS" section
- [ ] Images are embedded in Markdown
- [ ] ML-based recommendations are present
- [ ] DOCX conversion includes images

---

## ğŸ› Troubleshooting

### Issue: "ML data path does not exist"

**Solution**: Ensure ML analysis has been run first:

```bash
cd "ML V2"
python RUN_COMPLETE_ANALYSIS.py
```

### Issue: "ML insights unavailable"

**Cause**: ML data not found or analysis failed

**Solution**: 
1. Check ML data path exists
2. Verify ML analysis completed successfully
3. Check logs for specific errors
4. Report will continue without ML section (graceful degradation)

### Issue: Images not showing in Word

**Cause**: Relative paths may need adjustment

**Solution**:
1. Ensure images exist at specified paths
2. Convert Markdown to DOCX from correct directory
3. Check image paths are relative to report location

### Issue: "No linter errors" but agent not running

**Cause**: May need to reinstall dependencies

**Solution**:
```bash
conda activate sales_calls_ai_agent
pip install -r requirements.txt
```

---

## ğŸ“Š Sample Output

### ML Insights Section Preview

```markdown
# ğŸ¤– MACHINE LEARNING INSIGHTS

## ğŸ“Š Statistical Summary
Analyzed 49 variables across 1,220 calls | Random Forest ROC-AUC: 0.923 | 
XGBoost ROC-AUC: 0.918 | 42 variables show statistically significant differences

## ğŸ¯ Top 10 Most Important Variables
1. **customer_talk_percentage**
2. **total_discovery_questions**
3. **omc_agent_sentiment_style**
4. **customer_sentiment_omc**
5. **time_to_reason_seconds**
...

## ğŸ“ˆ Key ML Visualizations

### SHAP Waterfall Plot - Individual Prediction Explanation
*Shows how each variable contributes to pushing a call toward short or long duration*

![SHAP Waterfall](ML V2/analysis_outputs/level1_variable/shap_05_rf_waterfall.png)

### Top 20 Variables by Combined Importance
*Ranked by Random Forest, XGBoost, and Correlation analysis*

![Top 20 Variables](ML V2/analysis_outputs/level1_variable/viz_06_top_20_variables.png)

...
```

---

## ğŸ¯ Key Benefits

1. **Comprehensive Analysis**
   - Combines agentic AI + ML approaches
   - Cross-validates findings
   - Provides multiple perspectives

2. **Visual Evidence**
   - SHAP waterfall shows individual predictions
   - Feature importance shows overall patterns
   - Statistical tests show significance

3. **Actionable Insights**
   - ML identifies what matters
   - Agentic AI explains why
   - Combined recommendations prioritized by impact

4. **Explainability**
   - SHAP and LIME provide interpretability
   - Evidence for every insight
   - Methodology clearly documented

5. **Seamless Integration**
   - No breaking changes
   - Automatic execution
   - Graceful degradation if ML data unavailable

---

## ğŸ“š Additional Resources

- **Technical Summary**: `ML_INTEGRATION_SUMMARY.txt`
- **ML Analysis Scripts**: `ML V2/` directory
- **Test Script**: `test_ml_integration.py`
- **Agent Code**: `agents/ml_insights_agent.py`

---

## ğŸš€ Next Steps

1. **Run the analyzer** with ML integration
2. **Review the report** - check ML Insights section
3. **Verify visualizations** are embedded correctly
4. **Convert to DOCX** - ensure images appear
5. **Provide feedback** - what works, what needs improvement

---

## ğŸ’¡ Tips

- Run ML analysis (`RUN_COMPLETE_ANALYSIS.py`) before call analyzer for best results
- ML insights are cached during report generation (no re-analysis needed)
- If ML data unavailable, report continues without ML section
- Images use relative paths - keep directory structure intact
- DOCX conversion preserves embedded images

---

**Questions or Issues?**

Check logs in `logs/` directory for detailed execution information.

---

*Integration completed: December 22, 2024*
*Method: ReAct Pattern (Reasoning + Acting)*
*Status: âœ… Production Ready*

